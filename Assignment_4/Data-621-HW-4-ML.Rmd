---
title: "Data 621: Homework 4 - Data Exploration & Data Preparation"
author: "Matthew Lucich"
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, results = TRUE, fig.show = "show", message = FALSE)
```


```{r load-packages}
library(tidyverse)
library(ggplot2)
library(mice)
library(car)
library(Hmisc)
library(corrplot)
library(pscl)
library(boot)
```


### Load data

```{r}

# Load insurance csv
df_ins_raw <- read.csv("insurance_training_data.csv")

# Removing index as instructed
df_ins_raw <- subset(df_ins_raw, select = -c(INDEX))

# Preview data
glimpse(df_ins_raw)

```



## DATA CLEANING



### Fix formatting

```{r}


remove_z <-  function(x){
  str_replace(x, 'z_', '')
}

# Remove extraneous z_
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_z))


remove_dollar <-  function(x){
  str_replace(x, '\\$', '')
}

# Remove dollar sign from variables
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_dollar))

remove_comma <- function(x){
  str_replace(x, ',', '')
}

# Remove commas from variables
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_comma))

# Preview updated data
glimpse(df_ins_raw)

```



### Review distinct values

```{r}

# Count of distinct values for each column
df_ins_raw %>% summarise_all(n_distinct)

df_ins_raw %>% distinct(PARENT1)

df_ins_raw %>% distinct(MSTATUS)

df_ins_raw %>% distinct(SEX)

df_ins_raw %>% distinct(EDUCATION)

df_ins_raw %>% distinct(JOB)

df_ins_raw %>% distinct(CAR_USE)

df_ins_raw %>% distinct(CAR_TYPE)

df_ins_raw %>% distinct(CLM_FREQ)

df_ins_raw %>% distinct(REVOKED)

df_ins_raw %>% distinct(URBANICITY)

```




### Convert datatypes 

```{r}

# Set data types for variables
df_ins_clean <- df_ins_raw %>% transform( 
               TARGET_FLAG = as.factor(TARGET_FLAG), 
               TARGET_AMT = as.numeric(TARGET_AMT),
               KIDSDRIV = as.factor(KIDSDRIV),
               AGE = as.numeric(AGE),
               HOMEKIDS = as.factor(HOMEKIDS),
               YOJ = as.numeric(YOJ),
               INCOME = as.numeric(INCOME),
               PARENT1 = as.factor(PARENT1),
               HOME_VAL = as.numeric(HOME_VAL),
               MSTATUS = as.factor(MSTATUS),
               SEX = as.factor(SEX),
               EDUCATION = as.factor(EDUCATION),
               JOB = as.factor(JOB),
               TRAVTIME = as.numeric(TRAVTIME),
               CAR_USE = as.factor(CAR_USE),
               BLUEBOOK = as.numeric(BLUEBOOK),
               TIF = as.numeric(TIF), # factor or numeric?
               CAR_TYPE = as.factor(CAR_TYPE),
               RED_CAR = as.factor(RED_CAR),
               OLDCLAIM = as.numeric(OLDCLAIM),
               CLM_FREQ = as.ordered(CLM_FREQ),  # factor or numeric?
               REVOKED = as.factor(REVOKED),
               MVR_PTS = as.numeric(MVR_PTS),
               CAR_AGE = as.numeric(CAR_AGE),
               URBANICITY = as.factor(URBANICITY))

# Confirm CLM_FREQ is an ordered factor
is.ordered(df_ins_clean$CLM_FREQ)

```



### Review NAs

```{r}

# NA counts for each column
colSums(is.na(df_ins_clean))

# Visualize NA counts for each column
df_ins_clean  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()

```



### Data imputation

```{r}

# Impute data by regression: 
df_ins_imp <- mice(df_ins_clean, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_ins_imp <- complete(df_ins_imp)

# Confirm no NAs remain
colSums(is.na(df_ins_imp))

```



## DATA EXPLORATION

### Summary statistics

```{r}

describe(df_ins_imp)

```



### Distributions of variables

```{r}

# Histograms
df_ins_imp %>%
  keep(is.numeric) %>% 
  gather() %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_density(fill = "steelblue", alpha=0.9, color="steelblue") +
    geom_histogram(aes(y=..density..), alpha=0.5, fill = "lightblue", color="lightblue", position="identity")

# Boxplots
df_ins_imp %>%
  keep(is.numeric) %>% 
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_boxplot(fill = "steelblue", color="black", outlier.colour="red", outlier.shape=16,
             outlier.size=2, notch=FALSE)

```



### Distributions of log-transformed variables

```{r, warning=FALSE}

# Log transformation
df_ins_imp_log <- df_ins_imp %>% keep(is.numeric)
df_ins_imp_log <- log(df_ins_imp_log + 1)

# Histograms of log transformed numeric variables
df_ins_imp_log %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_log$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_log$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_log$AGE, col = "steelblue", lwd = 2)

```



### Distributions of square root-transformed variables

```{r, warning=FALSE}

# Square root transformation
df_ins_imp_sqrt <- sqrt(df_ins_imp %>% keep(is.numeric))

# Histograms of square root transformed numeric variables
df_ins_imp_sqrt %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_sqrt$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_sqrt$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_sqrt$AGE, col = "steelblue", lwd = 2)

```



### Distributions of cube root-transformed variables

```{r, warning=FALSE}

# Cube root transformation
df_ins_imp_cube <- (df_ins_imp %>% keep(is.numeric))^(1/3)

# Histograms of cube root transformed numeric variables
df_ins_imp_cube %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_cube$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_cube$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_cube$AGE, col = "steelblue", lwd = 2)

```



### Create new columns with transformed variables

```{r, warning=FALSE}

df_ins <- df_ins_imp %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(log = ~ log(. + 1))))

df_ins <- df_ins %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(sqrt = sqrt)))

df_ins <- df_ins %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(cbrt = ~ .^(1/3))))

glimpse(df_ins)

```



### Create new variables

```{r}

df_ins$HV_INC_RATIO <- df_ins$HOME_VAL / df_ins$INCOME

df_ins$TRT_MVR_PRODUCT <- df_ins$TRAVTIME * df_ins$MVR_PTS

df_ins$HV_INC_RATIO[is.nan(df_ins$HV_INC_RATIO)] <- 0
df_ins$HV_INC_RATIO[is.infinite(df_ins$HV_INC_RATIO)] <- 0

```


### Data imputation again

```{r}

# Impute data by regression: 
df_ins <- mice(df_ins, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_ins <- complete(df_ins)

# Confirm no NAs remain
colSums(is.na(df_ins))

```



### Correlation of variables

```{r}

# Visualize correlation between variables
corrplot(cor(df_ins_imp %>% keep(is.numeric)), method="shade", shade.col=NA, tl.col="black", tl.srt=45)

# Reshape correlation results
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

# Closer look at correlations of variables
corr_results <- rcorr(as.matrix(df_ins_imp %>% keep(is.numeric)))
df_corr <- flattenCorrMatrix(corr_results$r, corr_results$P)

# Noteworthy positive correlations
df_corr %>% filter(cor > 0.4)

# Noteworthy negative correlations
df_corr %>% filter(cor < -0.4)

# Pair plot
pairs(df_ins_imp %>% keep(is.numeric), lower.panel = NULL, col = "steelblue")

```


### Check for multicollinearity

```{r}

model <- glm(TARGET_AMT ~ KIDSDRIV + AGE + YOJ + INCOME + HOME_VAL + TRAVTIME + BLUEBOOK +
            TIF + OLDCLAIM + MVR_PTS + CAR_AGE, data = df_ins, family = "quasipoisson")

vif(model)

```


### Bucket select variables (by quantiles)

```{r}

# 0-.25, .25-.75, .75-1
df_ins$CAR_AGE_fact <- cut(x = df_ins$CAR_AGE, breaks = c(-4, 3.5, 12, 28), labels = c("New", "Moderate", "Old"))

# -.5, .5-.9, .9+
df_ins$HOME_VAL_fact <- cut(x = df_ins$HOME_VAL, breaks = c(-86567, 160953, 314151, 885283), labels = c("No or Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_ins$INCOME_fact <- cut(x = df_ins$INCOME, breaks = c(-31969, 27940, 85472, 367031), labels = c("Low", "Moderate", "High"))

# 0-.5, .50-.75, .75-1
df_ins$MVR_PTS_fact <- cut(x = df_ins$MVR_PTS, breaks = c(-1, 1, 3, 14), labels = c("Low", "Moderate", "High"))

# 0-.75, .75-1
df_ins$OLDCLAIM_fact <- cut(x = df_ins$OLDCLAIM, breaks = c(-1, 4636, 57038), labels = c("Low", "High"))

# 0-.25, .25-.75, .75-1
df_ins$TIF_fact <- cut(x = df_ins$TIF, breaks = c(-1, 1, 7, 26), labels = c("Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_ins$TRAVTIME_fact <- cut(x = df_ins$TRAVTIME, breaks = c(4, 22, 44, 143), labels = c("Short", "Moderate", "Long"))

# 0-.25, .25-.75, .75-1
df_ins$YOJ_fact <- cut(x = df_ins$YOJ, breaks = c(-1, 9, 13, 24), labels = c("Low", "Moderate", "High"))

```



### Temp model

```{r, warning=FALSE}

glm_model <- glm(TARGET_AMT ~ ., data = df_ins, family = "quasipoisson")

summary(glm_model)

plot(glm_model)

```


### References

http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

