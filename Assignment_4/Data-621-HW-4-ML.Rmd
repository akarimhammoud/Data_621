---
title: "DATA 621 Assignment 4"
author: "Critical Thinking Group 2: George Cruz Deschamps, Karim Hammoud, Maliat Islam, Matthew Lucich, Gabriella Maritnez, Ken Popkin"
date: "Date: `r Sys.Date()` | Due: 2021-11-21" 
output:
      html_document:
        toc: yes
        toc_float: yes
        theme: yeti
        highlight: kate
        font-family: "Arial"
        code_folding: "show"
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, results = TRUE, fig.show = "show", message = FALSE)
```


```{r load-packages}
library(tidyverse)
library(ggplot2)
library(mice)
library(car)
library(Hmisc)
library(corrplot)
library(pscl)
library(boot)
library(caret)
library(leaps)
library(MASS)
library(kableExtra)
library(summarytools)
```


### Load data

```{r}
# Load TRAIN insurance csv
df_ins_raw <- read.csv("https://raw.githubusercontent.com/akarimhammoud/Data_621/main/Assignment_4/data/insurance_training_data.csv")

# Removing index as instructed
df_ins_raw <- subset(df_ins_raw, select = -c(INDEX))

# Preview data
glimpse(df_ins_raw)
```

```{r}
#Load EVAL ins csv
df_eval_raw <- read.csv("https://raw.githubusercontent.com/akarimhammoud/Data_621/main/Assignment_4/data/insurance-evaluation-data.csv")

# Removing index as instructed
df_eval_raw <- subset(df_eval_raw, select = -c(INDEX))

# Preview data
glimpse(df_eval_raw)
```



## DATA CLEANING



### Fix formatting

```{r}
remove_z <-  function(x){
  str_replace(x, 'z_', '')
}

# Remove extraneous z_
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_z))


remove_dollar <-  function(x){
  str_replace(x, '\\$', '')
}

# Remove dollar sign from variables
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_dollar))

remove_comma <- function(x){
  str_replace(x, ',', '')
}

# Remove commas from variables
df_ins_raw <- mutate_all(df_ins_raw, funs(remove_comma))

# Preview updated data
glimpse(df_ins_raw)

```

```{r}
#Cleaning EVAL data
remove_z <-  function(x){
  str_replace(x, 'z_', '')
}

# Remove extraneous z_
df_eval_raw <- mutate_all(df_eval_raw, funs(remove_z))


remove_dollar <-  function(x){
  str_replace(x, '\\$', '')
}

# Remove dollar sign from variables
df_eval_raw <- mutate_all(df_eval_raw, funs(remove_dollar))

remove_comma <- function(x){
  str_replace(x, ',', '')
}

# Remove commas from variables
df_eval_raw <- mutate_all(df_eval_raw, funs(remove_comma))

# Preview updated data
glimpse(df_eval_raw)
```


### Review distinct values

```{r}
# TRAIN
# Count of distinct values for each column
df_ins_raw %>% summarise_all(n_distinct)

df_ins_raw %>% distinct(PARENT1)

df_ins_raw %>% distinct(MSTATUS)

df_ins_raw %>% distinct(SEX)

df_ins_raw %>% distinct(EDUCATION)

df_ins_raw %>% distinct(JOB)

df_ins_raw %>% distinct(CAR_USE)

df_ins_raw %>% distinct(CAR_TYPE)

df_ins_raw %>% distinct(CLM_FREQ)

df_ins_raw %>% distinct(REVOKED)

df_ins_raw %>% distinct(URBANICITY)

```




### Convert datatypes 

```{r}
#TRAIN
# Set data types for variables
df_ins_clean <- df_ins_raw %>% transform( 
               TARGET_FLAG = as.factor(TARGET_FLAG), 
               TARGET_AMT = as.numeric(TARGET_AMT),
               KIDSDRIV = as.factor(KIDSDRIV),
               AGE = as.numeric(AGE),
               HOMEKIDS = as.factor(HOMEKIDS),
               YOJ = as.numeric(YOJ),
               INCOME = as.numeric(INCOME),
               PARENT1 = as.factor(PARENT1),
               HOME_VAL = as.numeric(HOME_VAL),
               MSTATUS = as.factor(MSTATUS),
               SEX = as.factor(SEX),
               EDUCATION = as.factor(EDUCATION),
               JOB = as.factor(JOB),
               TRAVTIME = as.numeric(TRAVTIME),
               CAR_USE = as.factor(CAR_USE),
               BLUEBOOK = as.numeric(BLUEBOOK),
               TIF = as.numeric(TIF), # factor or numeric?
               CAR_TYPE = as.factor(CAR_TYPE),
               RED_CAR = as.factor(RED_CAR),
               OLDCLAIM = as.numeric(OLDCLAIM),
               CLM_FREQ = as.ordered(CLM_FREQ),  # factor or numeric?
               REVOKED = as.factor(REVOKED),
               MVR_PTS = as.numeric(MVR_PTS),
               CAR_AGE = as.numeric(CAR_AGE),
               URBANICITY = as.factor(URBANICITY))

# Confirm CLM_FREQ is an ordered factor
is.ordered(df_ins_clean$CLM_FREQ)

#Show level and counts of CLM_FREQ
table(df_ins_clean$CLM_FREQ)

#Convert Education to an ordered factor
df_ins_clean$EDUCATION <- ordered(df_ins_clean$EDUCATION,levels = c("<High School", "High School", "Bachelors", "Masters", "PhD"))

#Confirm if EDUCATION is ordered
is.ordered(df_ins_clean$EDUCATION)

#Show the levels
table(df_ins_clean$EDUCATION)

```

```{r}
#EVAL
# Set data types for variables
df_eval_clean <- df_eval_raw %>% transform( 
               TARGET_FLAG = as.factor(TARGET_FLAG), 
               TARGET_AMT = as.numeric(TARGET_AMT),
               KIDSDRIV = as.factor(KIDSDRIV),
               AGE = as.numeric(AGE),
               HOMEKIDS = as.factor(HOMEKIDS),
               YOJ = as.numeric(YOJ),
               INCOME = as.numeric(INCOME),
               PARENT1 = as.factor(PARENT1),
               HOME_VAL = as.numeric(HOME_VAL),
               MSTATUS = as.factor(MSTATUS),
               SEX = as.factor(SEX),
               EDUCATION = as.factor(EDUCATION),
               JOB = as.factor(JOB),
               TRAVTIME = as.numeric(TRAVTIME),
               CAR_USE = as.factor(CAR_USE),
               BLUEBOOK = as.numeric(BLUEBOOK),
               TIF = as.numeric(TIF), # factor or numeric?
               CAR_TYPE = as.factor(CAR_TYPE),
               RED_CAR = as.factor(RED_CAR),
               OLDCLAIM = as.numeric(OLDCLAIM),
               CLM_FREQ = as.ordered(CLM_FREQ),  # factor or numeric?
               REVOKED = as.factor(REVOKED),
               MVR_PTS = as.numeric(MVR_PTS),
               CAR_AGE = as.numeric(CAR_AGE),
               URBANICITY = as.factor(URBANICITY))

# Confirm CLM_FREQ is an ordered factor
is.ordered(df_eval_clean$CLM_FREQ)

#Show level and counts of CLM_FREQ
table(df_eval_clean$CLM_FREQ)

#Convert Education to an ordered factor
df_eval_clean$EDUCATION <- ordered(df_eval_clean$EDUCATION,levels = c("<High School", "High School", "Bachelors", "Masters", "PhD"))

#Confirm if EDUCATION is ordered
is.ordered(df_eval_clean$EDUCATION)

#Show the levels
table(df_eval_clean$EDUCATION)
```


### Review NAs

```{r}
#TRAIN
# NA counts for each column
colSums(is.na(df_ins_clean))

# Visualize NA counts for each column
df_ins_clean  %>%
  summarise_all(list(~is.na(.)))%>%
  pivot_longer(everything(),
               names_to = "variables", values_to="missing") %>%
  count(variables, missing) %>%
  ggplot(aes(y=variables,x=n,fill=missing))+
  geom_col()

```



### Data imputation

```{r}
#TRAIN
# Impute data by regression: 
df_ins_imp <- mice(df_ins_clean, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_ins_imp <- complete(df_ins_imp)

# Confirm no NAs remain
colSums(is.na(df_ins_imp))

```


```{r}
#EVAL
# Impute data by regression: 
df_eval_imp <- mice(df_eval_clean, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_eval_imp <- complete(df_eval_imp)

# Confirm no NAs remain
colSums(is.na(df_eval_imp))
```


_____
_____

## DATA EXPLORATION

### Summary statistics

```{r}

describe(df_ins_imp)

descr(df_ins_imp,
  headings = FALSE, #remove headings# 
  transpose = FALSE #TRUE allows for better display due to large amount of variables
  ) %>% 
  kbl(caption = "Univariate Descriptive Statistics - Training Data Set") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```



### Distributions of variables

```{r}

# Histograms
df_ins_imp %>%
  keep(is.numeric) %>% 
  gather() %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales = "free") +
    geom_density(fill = "steelblue", alpha=0.9, color="steelblue") +
    geom_histogram(aes(y=..density..), alpha=0.5, fill = "lightblue", color="lightblue", position="identity")

# Boxplots
df_ins_imp %>%
  keep(is.numeric) %>% 
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_boxplot(fill = "steelblue", color="black", outlier.colour="red", outlier.shape=16,
             outlier.size=2, notch=FALSE)

```



### Distributions of log-transformed variables

```{r, warning=FALSE}

# Log transformation
df_ins_imp_log <- df_ins_imp %>% keep(is.numeric)
df_ins_imp_log <- log(df_ins_imp_log + 1)

# Histograms of log transformed numeric variables
df_ins_imp_log %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_log$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_log$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_log$AGE, col = "steelblue", lwd = 2)

```

```{r}
#EVAL
# Log transformation
df_eval_imp_log <- df_eval_imp %>% keep(is.numeric)
df_eval_imp_log <- log(df_eval_imp_log + 1)
```



### Distributions of square root-transformed variables

```{r, warning=FALSE}

# Square root transformation
df_ins_imp_sqrt <- sqrt(df_ins_imp %>% keep(is.numeric))

# Histograms of square root transformed numeric variables
df_ins_imp_sqrt %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_sqrt$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_sqrt$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_sqrt$AGE, col = "steelblue", lwd = 2)

```

```{r}
#EVAL
# Square root transformation
df_eval_imp_sqrt <- sqrt(df_eval_imp %>% keep(is.numeric))
```


### Distributions of cube root-transformed variables

```{r, warning=FALSE}

# Cube root transformation
df_ins_imp_cube <- (df_ins_imp %>% keep(is.numeric))^(1/3)

# Histograms of cube root transformed numeric variables
df_ins_imp_cube %>%
  gather(variable, value, TARGET_AMT:CAR_AGE) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())

# Test for normality
shapiro.test(df_ins_imp_cube$AGE[0:5000])

# Visual inspection of one variable (age) for normality
qqnorm(df_ins_imp_cube$AGE, pch = 1, frame = FALSE)
qqline(df_ins_imp_cube$AGE, col = "steelblue", lwd = 2)

```

```{r}
#EVAL
# Cube root transformation
df_eval_imp_cube <- (df_eval_imp %>% keep(is.numeric))^(1/3)
```


### Create new columns with transformed variables

```{r, warning=FALSE}

df_ins <- df_ins_imp %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(log = ~ log(. + 1))))

df_ins <- df_ins %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(sqrt = sqrt)))

df_ins <- df_ins %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(cbrt = ~ .^(1/3))))

glimpse(df_ins)

```

```{r}
#EVAL
df_eval <- df_eval_imp %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(log = ~ log(. + 1))))

df_eval <- df_eval %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(sqrt = sqrt)))

df_eval <- df_eval %>%
                  mutate(across(c(TARGET_AMT, AGE, YOJ, INCOME, HOME_VAL, TRAVTIME, BLUEBOOK, 
                                  TIF, OLDCLAIM, MVR_PTS, CAR_AGE), .fns = list(cbrt = ~ .^(1/3))))
```



### Create new variables

```{r}

df_ins$HV_INC_RATIO <- df_ins$HOME_VAL / df_ins$INCOME

df_ins$TRT_MVR_PRODUCT <- df_ins$TRAVTIME * df_ins$MVR_PTS

df_ins$HV_INC_RATIO[is.nan(df_ins$HV_INC_RATIO)] <- 0
df_ins$HV_INC_RATIO[is.infinite(df_ins$HV_INC_RATIO)] <- 0

```

```{r}
#EVAL
df_eval$HV_INC_RATIO <- df_eval$HOME_VAL / df_eval$INCOME

df_eval$TRT_MVR_PRODUCT <- df_eval$TRAVTIME * df_eval$MVR_PTS

df_eval$HV_INC_RATIO[is.nan(df_eval$HV_INC_RATIO)] <- 0
df_eval$HV_INC_RATIO[is.infinite(df_eval$HV_INC_RATIO)] <- 0
```


### Data imputation again

```{r}

# Impute data by regression: 
df_ins <- mice(df_ins, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_ins <- complete(df_ins)

# Confirm no NAs remain
colSums(is.na(df_ins))

```


```{r}
# Impute data by regression: 
df_eval <- mice(df_eval, method = "norm.predict", m = 1, remove.collinear=FALSE)
df_eval <- complete(df_eval)

# Confirm no NAs remain
colSums(is.na(df_eval))


```


### Correlation of variables

```{r}

# Visualize correlation between variables
corrplot.mixed(cor(df_ins_imp %>% keep(is.numeric)), tl.col = 'black', tl.pos = 'lt', upper = "number", lower="shade", shade.col=NA, tl.srt=45)

# Reshape correlation results
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

# Closer look at correlations of variables
corr_results <- rcorr(as.matrix(df_ins_imp %>% keep(is.numeric)))
df_corr <- flattenCorrMatrix(corr_results$r, corr_results$P)

# Noteworthy positive correlations
df_corr %>% filter(cor > 0.4)

# Noteworthy negative correlations
df_corr %>% filter(cor < -0.4)

# Pair plot
pairs(df_ins_imp %>% keep(is.numeric), lower.panel = NULL, col = "steelblue")

```


### Check for multicollinearity

```{r}

model <- glm(TARGET_AMT ~ KIDSDRIV + AGE + YOJ + INCOME + HOME_VAL + TRAVTIME + BLUEBOOK +
            TIF + OLDCLAIM + MVR_PTS + CAR_AGE, data = df_ins, family = "quasipoisson")

vif(model)

```


### Bucket select variables (by quantiles)

```{r}

# 0-.25, .25-.75, .75-1
df_ins$CAR_AGE_fact <- cut(x = df_ins$CAR_AGE, breaks = c(-4, 3.5, 12, 28), labels = c("New", "Moderate", "Old"))

# -.5, .5-.9, .9+
df_ins$HOME_VAL_fact <- cut(x = df_ins$HOME_VAL, breaks = c(-86567, 160953, 314151, 885283), labels = c("No or Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_ins$INCOME_fact <- cut(x = df_ins$INCOME, breaks = c(-31969, 27940, 85472, 367031), labels = c("Low", "Moderate", "High"))

# 0-.5, .50-.75, .75-1
df_ins$MVR_PTS_fact <- cut(x = df_ins$MVR_PTS, breaks = c(-1, 1, 3, 14), labels = c("Low", "Moderate", "High"))

# 0-.75, .75-1
df_ins$OLDCLAIM_fact <- cut(x = df_ins$OLDCLAIM, breaks = c(-1, 4636, 57038), labels = c("Low", "High"))

# 0-.25, .25-.75, .75-1
df_ins$TIF_fact <- cut(x = df_ins$TIF, breaks = c(-1, 1, 7, 26), labels = c("Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_ins$TRAVTIME_fact <- cut(x = df_ins$TRAVTIME, breaks = c(4, 22, 44, 143), labels = c("Short", "Moderate", "Long"))

# 0-.25, .25-.75, .75-1
df_ins$YOJ_fact <- cut(x = df_ins$YOJ, breaks = c(-1, 9, 13, 24), labels = c("Low", "Moderate", "High"))

```

```{r}
glimpse(df_ins)
```

```{r}
#EVAL
# 0-.25, .25-.75, .75-1
df_eval$CAR_AGE_fact <- cut(x = df_eval$CAR_AGE, breaks = c(-4, 3.5, 12, 28), labels = c("New", "Moderate", "Old"))

# -.5, .5-.9, .9+
df_eval$HOME_VAL_fact <- cut(x = df_eval$HOME_VAL, breaks = c(-86567, 160953, 314151, 885283), labels = c("No or Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_eval$INCOME_fact <- cut(x = df_eval$INCOME, breaks = c(-31969, 27940, 85472, 367031), labels = c("Low", "Moderate", "High"))

# 0-.5, .50-.75, .75-1
df_eval$MVR_PTS_fact <- cut(x = df_eval$MVR_PTS, breaks = c(-1, 1, 3, 14), labels = c("Low", "Moderate", "High"))

# 0-.75, .75-1
df_eval$OLDCLAIM_fact <- cut(x = df_eval$OLDCLAIM, breaks = c(-1, 4636, 57038), labels = c("Low", "High"))

# 0-.25, .25-.75, .75-1
df_eval$TIF_fact <- cut(x = df_eval$TIF, breaks = c(-1, 1, 7, 26), labels = c("Low", "Moderate", "High"))

# 0-.25, .25-.75, .75-1
df_eval$TRAVTIME_fact <- cut(x = df_eval$TRAVTIME, breaks = c(4, 22, 44, 143), labels = c("Short", "Moderate", "Long"))

# 0-.25, .25-.75, .75-1
df_eval$YOJ_fact <- cut(x = df_eval$YOJ, breaks = c(-1, 9, 13, 24), labels = c("Low", "Moderate", "High"))
```

_____
_____

## BUILD MODELS
### Multiple Regression Models

^[https://cmdlinetips.com/2020/10/4-ways-to-select-columns-from-a-dataframe-with-dplyrs-select/]
```{r}
df_ins_mrm <- df_ins %>% 
  dplyr::select(-TARGET_FLAG, -TARGET_AMT, -TARGET_AMT_sqrt, -TARGET_AMT_cbrt) %>% 
  dplyr::select(TARGET_AMT_log,where(is.factor),BLUEBOOK_cbrt,INCOME_cbrt,MVR_PTS_cbrt,OLDCLAIM_cbrt,TRAVTIME_cbrt,
                CAR_AGE_sqrt,HOME_VAL_sqrt,YOJ_sqrt, TIF_log)
  
```

### Baseline Model

First, we will begin by creating our base model by modelling the response variable `TARGET_AMT_log` to all the features.
```{r message=FALSE, warning=FALSE}
#fit the base lm model with no adjustments
base.model <- train(TARGET_AMT_log ~., data = df_ins_mrm, method = "lm")

summary(base.model$finalModel)
```

Here are the results of our `base.model`, with an RMSE seen below.
```{r}
base.model$results
```

### Forward Stepwise Model

```{r message=FALSE, warning=FALSE}
# Set seed for reproducibility
set.seed(123)
# Set up repeated k-fold cross-validation
train.control <- trainControl(method = "repeatedcv",   
                           number = 20, repeats = 5,
                           search = "grid")
# Train the model
step.model <- train(TARGET_AMT_log ~., data = df_ins_mrm,
                    method = "leapForward", 
                    tuneGrid = data.frame(nvmax = 1:10),
                    trControl = train.control
                    )
step.model
```

Based on the RMSE from `step.model$results`, we see that model ten of the ten produced is the best performing model. This can also be confirmed by the below function as well, `step.model$bestTune`.
```{r message=FALSE, warning=FALSE}
step.model$bestTune
```

Using the `coef()` function, we see that the feature variables and corresponding coefficients for the "best" performing model from the forward stepwise method using `StepAIC()` are:
```{r message=FALSE, warning=FALSE}
coef(step.model$finalModel, 10)
```

### Lasso Model

As an additional model, we will run a Lasso method with our `train()` function by specifying `method = "lasso"`. 
```{r message=FALSE, warning=FALSE}
set.seed(456)
fit.control <- trainControl(method = "repeatedcv",   
                           number = 20, repeats = 5,
                           search = "random")    

lasso.model <- train(TARGET_AMT_log ~ .,
               data = df_ins_mrm,
               method = "lasso",  # now we're using the lasso method
               trControl = fit.control,
               na.action = na.omit) 

lasso.model
```

### Ridge Regression Model

Next, we run a Ridge Regression model with our `train()` function by specifying `method = "ridge"`
```{r message=FALSE, warning=FALSE}
set.seed(789)
fit.control <- trainControl(method = "repeatedcv",   
                           number = 20, repeats = 5,
                           search = "random")    

ridge.model <- train(TARGET_AMT_log ~ .,
               data = df_ins_mrm,
               method = "ridge",  
               trControl = fit.control,
               na.action = na.omit) 

ridge.model
```

Using the `varImp()` function of the `caret` package, we can see which are the most important variables for our model.The return of `varImp()` can be passed to the `ggplot()` function to generate a visualization.^[https://towardsdatascience.com/create-predictive-models-in-r-with-caret-12baf9941236]
```{r}
ggplot(varImp(ridge.model))
```

_____
_____

## SELECT MODELS
### Multiple Regression Model

Using the RMSE as out selection metric, of the three models produced above, forward stepwise, ridge regression, and lasso, we find that the best of the three is the ridge regression method with an RMSE of 3.246734.

```{r}
df_eval_mrm <- df_eval %>% 
  dplyr::select(-TARGET_FLAG, -TARGET_AMT, -TARGET_AMT_sqrt, -TARGET_AMT_cbrt) %>% 
  dplyr::select(TARGET_AMT_log,where(is.factor),BLUEBOOK_cbrt,INCOME_cbrt,MVR_PTS_cbrt,OLDCLAIM_cbrt,TRAVTIME_cbrt,
                CAR_AGE_sqrt,HOME_VAL_sqrt,YOJ_sqrt, TIF_log)
```

```{r}
predictions <- predict(ridge.model, df_eval_mrm)
summary(predictions)
```

```{r}
predicion_df <- as.data.frame(predictions) #create df for ggplot
ggplot(predicion_df, aes(x=predictions)) + 
 geom_histogram(aes(y=..density..), colour="black", fill="white")+
 geom_density(alpha=.2, fill="#E69F00")+
labs(title="Predicted Value",x="TARGET_AMT", y = "Density")
```

_____
_____
## References

http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

