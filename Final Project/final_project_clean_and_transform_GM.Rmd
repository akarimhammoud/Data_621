---
title: "DATA621: Final Project"
author: "Group 2: George Cruz Deschamps, Karim Hammoud, Maliat Islam, Gabriella Maritnez, Ken Popkin"
date: "Date: `r Sys.Date()` Due:2021-12-12" 
output:
      html_document:
        toc: yes
        toc_float: yes
        theme: yeti
        highlight: kate
        font-family: "Arial"
        code_folding: "show"
---

## Overview
There are millions of stray pets around the world, some of which are fortunate enough to be adopted while many others are not.  While adoption of a pet is often the definition of success, the rate at which a pet is adopted is also a key success factor - pets that take a long time to adopt contribute to over-crowded animal shelters and can prevent taking on new strays.  Sadly, pets that are not adopted eventually need to be euthanized.

### Learn more about the data
[About the data](https://www.kaggle.com/c/petfinder-adoption-prediction/data)

- PetID - Unique hash ID of pet profile
- AdoptionSpeed - **response variable** Categorical speed of adoption. Lower is faster. 
- Type - Type of animal (1 = Dog, 2 = Cat)
- Name - Name of pet (Empty if not named)
- Age - Age of pet when listed, in months
- Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)
- Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)
- Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)
- Color1 - Color 1 of pet (Refer to ColorLabels dictionary)
- Color2 - Color 2 of pet (Refer to ColorLabels dictionary)
- Color3 - Color 3 of pet (Refer to ColorLabels dictionary)
- MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)
- FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)
- Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)
- Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)
- Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)
- Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)
- Quantity - Number of pets represented in profile
- Fee - Adoption fee (0 = Free)
- State - State location in Malaysia (Refer to StateLabels dictionary)
- RescuerID - Unique hash ID of rescuer
- VideoAmt - Total uploaded videos for this pet
- PhotoAmt - Total uploaded photos for this pet
- Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.

### What to Predict
Predictor (Adoption Speed) Description: Predict how quickly, if at all, a pet is adopted.

The values are determined in the following way:

- 0 - Pet was adopted on the same day as it was listed.
- 1 - Pet was adopted between 1 and 7 days (1st week) after being listed.
- 2 - Pet was adopted between 8 and 30 days (1st month) after being listed.
- 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.
- 4 - No adoption after 100 days of being listed.


## Packages
```{r message=FALSE, warning=FALSE}
library(dplyr)
library(reshape)
library(ggplot2)
library(purrr)
library(psych)
library(tidyr)
library(corrplot)
library(forcats)
library(kableExtra)
library(summarytools)
library(stats)
library(GGally)
library(wordcloud)
library(Amelia)
library(MASS)
library(Hmisc)
library(foreign)
library(reshape2)
library(splines)
library(car)
library(effects)
```

## Load Data

```{r}
# load data https://raw.githubusercontent.com/akarimhammoud/Data_621/main/Final%20Project/data/TrainingData/traindatawithbreedname.csv
data <- read.csv('./data/TrainingData/traindatawithbreedname.csv')
#data <- read.csv('./data/TestData/test.csv')
head(data,2)
```

## Data Cleaning and Feature Engineering

### Missing Values Count 
There are no missing values
```{r}
map(data, ~sum(is.na(.))) %>% t()
```

### Show the type of each data
```{r}
str(data)
```

### New features
AgeYears - provided in months this is too many variations.  Decided to convert to new feature of AgeYears and drop Age
```{r}
data$AgeYears = round(data$Age/12, 0)
```

NumColors - derived by counting the number of colors a pet has using the Color1,2, and 3 features
- keep these features, but given there are 7 color categories the value of this feature is questionable in doubt
- create a NumColors feature with a 1,2, or 3 respectively
```{r}
num_colors_vec = c()
for (i in 1:nrow(data)){
  ncolors = 1
  
  color2 <- data[i,8]
  color3 <- data[i,9]
  
  if (color2 > 0){ncolors = ncolors + 1}
  if (color3 > 0){ncolors = ncolors + 1}
  
  num_colors_vec <- c(num_colors_vec, ncolors)
}

data$NumColors = num_colors_vec
```

AllMeds = the sum of Vaccinated, Dewormed, and Sterilized.  Combining these into one feature could potentially reduce
multi-collinearity
```{r}
data$AllMeds = data$Vaccinated + data$Dewormed + data$Sterilized
```

### Remove features 
Remove the following features...
Name - this is a text field and new owners can (and usually do) rename their pets, so removing this feature
Age - replaced with AgeYears (see above)
Breed2 - 10,700 of almost 15,000 rows are populated with 0 (unknown), so this doesn't seem like a good feature to keep
State - initially kept this, but the correlation to AdoptionSpeed is only about 2%.  Decided to remove it
RescuerID - common sense is that this field will not have any predictive value for adoption rate
Description - this will have value in future analysis for NLP, but this will be evaluated differently in another notebook
PetID - same reason as RescuerID

```{r}
data = subset(data, select = -c(Name, Age, Breed2, State, RescuerID, Description, PetID))
```

### Show the updated data type
```{r}
sapply(data,class)
```

#Change categorical variables from integer to factors
```{r}
data <- transform(
  data,
  Type=as.factor(Type),
  Breed1=as.factor(Breed1),
  Gender=as.factor(Gender),
  Color1=as.factor(Color1),
  Color2=as.factor(Color2),
  Color3=as.factor(Color3),
  MaturitySize=as.factor(MaturitySize),
  FurLength=as.factor(FurLength),
  Vaccinated = as.factor(Vaccinated),
  Dewormed = as.factor(Dewormed),
  Sterilized = as.factor(Sterilized),
  Health = as.factor(Health),
  AdoptionSpeed = as.factor(AdoptionSpeed),
  NumColors = as.factor(NumColors)
)
```

```{r}
str(data)
```

### Add Labels 

```{r}
data$Type <- recode_factor(data$Type, "1" = "Dog",
                           "2"= "Cat")
```


Import the color labels to see the names of the colors.
```{r}
colors <- read.csv('./data/color_labels.csv')

glimpse(colors)
```
Checking the levels of `Color1`, `Color2`, and `Color3`

```{r}
levels(data$Color1)
```
```{r}
levels(data$Color2)
```

```{r}
levels(data$Color3)
```

Add labels to the colors.

```{r}
data$Color1 <- recode_factor(data$Color1,"1"= "Black", 
                                "2"= "Brown", 
                                "3"= "Golden", 
                                "4"= "Yellow", 
                                "5"= "Cream", 
                                "6"= "Gray", 
                                "7"= "White")
  
```

```{r}
data$Color2 <- recode_factor(data$Color2, "0" = "NA",
                                "2"= "Brown", 
                                "3"= "Golden", 
                                "4"= "Yellow", 
                                "5"= "Cream", 
                                "6"= "Gray", 
                                "7"= "White")
```

```{r}
data$Color3 <- recode_factor(data$Color3, "0" = "NA",
                                "3"= "Golden", 
                                "4"= "Yellow", 
                                "5"= "Cream", 
                                "6"= "Gray", 
                                "7"= "White")
```

Converting the `char` version of "NA" introduced in `ColorName`s 1-3 to type NA.
```{r}
data[data=="NA"]<-NA
```

Adding labels to `Gender` variable per definitions assigned to create `GenderLabel`.
```{r}
#data$GenderLabel
data$Gender <- recode_factor(data$Gender, "1" = "Male",
                                  "2" = "Female",
                                  "3" = "Mixed")
```

Adding labels to `MaturitySize`.
```{r}
#levels(data$MaturitySize)
#MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)
#data$MaturitySizeLabel
data$MaturitySize <- recode_factor(data$MaturitySize, "1" = "Small", 
                                   "2" = "Medium",
                                   "3" = "Large",
                                   "4" = "Extra Large")
```

```{r}
#1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified
data$Health <-recode_factor(data$Health, 
                                   "1" = "Healthy", 
                                   "2" = "Minor Injury", 
                                   "3" = "Serious Injury")
```

```{r}
#FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)
data$FurLength <-recode_factor(data$FurLength, 
                                   "1" = "Short", 
                                   "2" = "Medium", 
                                   "3" = "Long")
```

Adding labels to `Vaccinated`, `Dewormed`, `Sterilized`. A number of observations in these columns are `Not Sure` which can be interpreted as `NA`. Similarly, the `VideoAmt` variable contains 14419 observations with 0 videos so the 0s have been converted to `NA`.  

Part of the code in the blocks below can be commented out if we want to preserve the `Not Sure` and the 0 values.
```{r}
data$Vaccinated <-recode_factor(data$Vaccinated, 
                                   "1" = "Yes",
                                   "2" = "No",
                                   "3" = "Not Sure")
data$Dewormed <-recode_factor(data$Dewormed, 
                                   "1" = "Yes",
                                   "2" = "No",
                                   "3" = "Not Sure")
data$Sterilized <-recode_factor(data$Sterilized, 
                                   "1" = "Yes",
                                   "2" = "No",
                                   "3" = "Not Sure")

#turns the Not Sure into NAs comment the below out if we want to preserve the Not Sures
#levels(data$Vaccinated)[levels(data$Vaccinated)=='Not Sure'] <- NA
#levels(data$Dewormed)[levels(data$Dewormed)=='Not Sure'] <- NA
#levels(data$Sterilized)[levels(data$Sterilized)=='Not Sure'] <- NA
```

```{r}
table(data$VideoAmt)

#turns the 0 videoamout to NA 
data$VideoAmt[data$VideoAmt == 0] <- NA
```
Converting the `breedname` and `AllMeds` variables to factor since the original data points used to create these were factors.
```{r}
data$breedname <- as.factor(data$breedname)

data$AllMeds <- as.factor(data$AllMeds)
```

```{r}
data$breedname <- gsub("Amer ", "American ", data$breedname) 
```

Next we will collapse duplicate Labrador Retriever factors (Black, Chocolate, and Yellow) into one as they are not considered to be separate [Retriever breeds](https://www.akc.org/expert-advice/dog-breeds/retriever-breeds/). We will also group 4 of the Jack Russell Terrier (Parson Russell Terrier) breeds into Jack Russell Terrier.
```{r}
data$breedname <- fct_collapse(data$breedname, 
                                   'Labrador Retriever' = 
                                     c("Black Labrador Retriever",
                                       "Chocolate Labrador Retriever",
                                       "Yellow Labrador Retriever"))
data$breedname <- fct_collapse(data$breedname,
                                   'Jack Russell Terrier' = 
                                     "Jack Russell Terrier (Parson Russell Terrier)")

```

```{r}
data$purebreed <- ifelse(data$breedname != "Mixed Breed", "Yes", "No")

data$purebreed<-  as.factor(data$purebreed)
```


## Exploratory Data Analysis

Next we will check our dataset to see if the new variables are worth keeping and detect other missing data.
```{r}
#remove duplicate variables
data <- data %>% 
  dplyr::select(-c(Breed1))

str(data)
```
### Visualizing missing data

```{r fig.height=7, fig.width=10}
map(data, ~sum(is.na(.))) %>% t()
missmap(data, main = "Missing vs Observed Values")
```

After making this visualization, it is best to remove the variables `VideoAmt`, `ColorName2`, and `ColorName3`.

```{r}
#make copy
train_data <- data
#remove NA
train_data <-train_data %>% 
  dplyr::select(-c(VideoAmt,Color2,Color3))
```

```{r}
map(train_data, ~sum(is.na(.))) %>% t()
missmap(train_data, main = "Missing vs Observed Values")
```


### Dog Breed Word Cloud

Below we use `wordcloud` to visualize the dog breeds in our data. Note the Mixed Breed has been removed as it was skewing our data with the highest number of observations with 5923 total.

```{r}
set.seed(123)
dogs <- train_data %>% 
  filter(Type== "Dog")

wordtable <- table(dogs$breedname) %>% 
  as.data.frame() %>% 
  filter(Freq >0) %>% 
  arrange(desc(Freq)) %>% 
  slice(c(-1))

wordcloud(words = wordtable$Var1, freq = wordtable$Freq,
          max.words=250,random.order=FALSE, scale=c(2,.8),
          rot.per=0.1, colors=brewer.pal(8, "Dark2"))
```

### Cat Breed Word Cloud

Below we use `wordcloud` to visualize the cat breeds in our data.
```{r}
set.seed(456)
cats <- train_data %>% 
  filter(Type== "Cat")

wordtable2 <- table(cats$breedname) %>% 
  as.data.frame() %>% 
  filter(Freq >0) %>% 
  arrange(desc(Freq)) 

wordcloud(words = wordtable2$Var1, freq = wordtable$Freq,
          max.words=250,random.order=FALSE, scale=c(2,.8),
          rot.per=0.1, colors=brewer.pal(8, "Dark2"))
```

### Bar plots

As part of exploring the data, below we look into our response variable and see which level of `AdoptionSpeed` has the most occurrences.   
As a reminder from above, below is the legend for our `AdoptionSpeed` factor levels.  
  
Predictor (Adoption Speed) Description: Predict how quickly, if at all, a pet is adopted.  
  
The values are determined in the following way:  

- 0: Pet was adopted on the same day as it was listed.
- 1: Pet was adopted between 1 and 7 days (1st week) after being listed.
- 2: Pet was adopted between 8 and 30 days (1st month) after being listed.
- 3: Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. 
- 4: No adoption after 100 days of being listed.  

Below we see that most dogs don't get adopted after 100 days of being listed. The next highest level would be adoption within the first month of listing.
```{r}

#fct_reorder(factor(AdoptionSpeed),Count
train_data %>% 
  group_by(AdoptionSpeed) %>%
  summarise(Count = length(AdoptionSpeed)) %>% 
  ggplot(aes(x=(AdoptionSpeed), 
             y= Count))+
  geom_col(position="dodge", fill= "steelblue")+
  geom_text(aes(label = Count, vjust = 1))+
  #coord_flip()+
  labs(x= "Adoption Speed", y = "Count")+
  theme_minimal()

```

```{r message=FALSE, warning=FALSE}
train_data %>% 
  group_by(PhotoAmt) %>%
  summarise(Count = length(PhotoAmt)) %>% 
  arrange(desc(Count)) %>% 
  top_n(10) %>% 
  ggplot(aes(x=fct_reorder(factor(PhotoAmt),Count), 
             y= Count))+
  geom_col(position="dodge", fill= "steelblue")+
  geom_text(aes(label = Count, hjust = 1))+
  coord_flip()+
  labs(x= "Photos per Listing", y = "Listing Count")+
  theme_minimal()
```

Below is a visual showing the amount of dogs per observation. The majority of the observation are single dog listings, but there are a number of listings with multiple dogs which in some cases may be a litter or two of dogs under one listing.
```{r message=FALSE, warning=FALSE}
train_data %>% 
  group_by(Quantity) %>%
  summarise(Count = length(Quantity)) %>% 
  arrange(desc(Count)) %>% 
  top_n(5)%>% 
  ggplot(aes(x=fct_reorder(factor(Quantity),Count), 
             y= Count))+
  geom_col(position="dodge", fill= "steelblue")+
  geom_text(aes(label = Count, hjust = 1))+
  coord_flip()+
  labs(x= "Pets per Listing", y = "Listing Count")+
  theme_minimal()
```

### Distributions of Numeric Variables

Here we are subsetting our numeric predictor variables to check their distributions.
```{r}
#subset our 3 vars
distributions <- train_data %>% 
  keep(is.numeric)
```

Next we check if the variables contain any NA values.
```{r}
colSums(is.na(distributions))
```

```{r}
#plot
distributions %>% 
  gather(variable, value, 1:4) %>%
  ggplot(aes(value)) +
    facet_wrap(~variable, scales = "free") +
    geom_density(fill = "steelblue", alpha=0.9, color="steelblue") +
    geom_histogram(aes(y=..density..), alpha=0.2, fill = "lightblue", color="lightblue", position="identity") +
    theme_minimal()
```
```{r}
#box plots
distributions %>% 
  gather() %>%
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_boxplot(fill = "steelblue", color="black", outlier.colour="red", outlier.shape=16,
             outlier.size=2, notch=FALSE) +
  theme_minimal()
```

```{r}
#stats
descr(distributions, 
  headings = FALSE, #remove headings# 
  transpose = FALSE #TRUE allows for better display due to large amount of variables
  ) %>% 
  kbl(caption = "Univariate Descriptive Statistics - Training Data Set") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### Transformations of numeric variables

Next we will take transformations of the variables reviewed above to see if the transformed variables are worth looking into and using for our model.

#### Log Transformations
```{r}
log_distributions <- log(distributions + 1)

# Histograms of log transformed numeric variables
log_distributions %>%
  gather(variable, value, 1:4) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 2) +
  labs(x = element_blank(), y = element_blank()) +
  theme_minimal()
```
  
#### Square Root transformations
```{r}
sqrt_distributions <- sqrt(distributions)

sqrt_distributions %>% 
  gather(variable, value, 1:4) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 2) +
  labs(x = element_blank(), y = element_blank()) +
  theme_minimal()
```
  
#### Cube root transformations
```{r}
cbrt_distributions <- (distributions)^(1/3)

cbrt_distributions %>% 
  gather(variable, value, 1:4) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "steelblue", color="steelblue") + 
  facet_wrap(~variable, scales ="free", ncol = 2) +
  labs(x = element_blank(), y = element_blank()) +
  theme_minimal()
```

Based on the above, all variables are still heavily right skewed with the exception of `PhotoAmt` which made some improvement, but still not normally distributed. 

### Correlation Plot

```{r}
numeric_values <- train_data 

numeric_values<- numeric_values %>% 
  select_if(is.numeric)
 
train_cor <- cor(numeric_values)
corrplot.mixed(train_cor, tl.col = 'black', tl.pos = 'lt', upper = "number", lower="circle")

```

## Build Model

Below we create a new feature based on the response variable `euth_risk`, which is a tri-level variable to condense the original `AdoptionSpeed`.  ^[https://www.nature.com/articles/s41598-021-87649-2] ^[https://bmcvetres.biomedcentral.com/articles/10.1186/s12917-020-02728-2]
```{r}
train_data$euth_risk<- fct_collapse(train_data$AdoptionSpeed,
                              'Low' = c("0", "1"),
                              'Medium' = c("2","3"),
                              'High' = "4")
levels(train_data$euth_risk)
```

```{r}
#removing breedname as it has too many factor levels
train_data <- train_data %>% 
  dplyr::select(-breedname)
```


```{r}
summary(train_data)
```


```{r fig.height=8, fig.width=10}
ggplot(train_data, aes(x = euth_risk, y = AgeYears, fill = euth_risk)) +
  geom_boxplot(size = .75) +   facet_grid(MaturitySize ~ Gender, margins = FALSE) +   
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

### ORDINAL LOGISTIC REGRESSION

The following models will be created using ordinal logisitic regression given the nature of the response variable as it can be considered an ordinal factor. ^[https://stats.idre.ucla.edu/r/dae/ordinal-logistic-regression/]  

#### Selecting an ordered variable

Below we run two null models, one with our original response variable `AdoptionSpeed`, and one with our created response variable `euth_risk`.
```{r}
null_model2 <- polr(AdoptionSpeed ~ 1 , train_data, Hess=TRUE)

summary(null_model2)
```

```{r}
null_model <- polr(euth_risk ~ 1 , train_data, Hess=TRUE)

summary(null_model)
```
AIC is used to compare different possible models and determine which one is the best fit for the data. By itself, the AIC score is not of much use unless it is compared with the AIC score of a competing model.  

The model with the lower AIC score is expected to strike a superior balance between its ability to fit the data set and its ability to avoid over-fitting the data set. ^[https://timeseriesreasoning.com/contents/akaike-information-criterion/]  


Using the AIC value, we see the model using the `euth-risk` may be a better fit.

```{r}
model_1 <- polr(euth_risk~ Type+(Gender+Color1+MaturitySize+
                                 FurLength+Health+Quantity+
                                 Fee+PhotoAmt+AgeYears+
                                 NumColors+purebreed+
                                 Vaccinated+Dewormed+Sterilized), 
              train_data, 
              Hess=TRUE)

summary(model_1)
```

### Assumptions: Detecting Multicollinearity
The R function vif() [car package] can be used to detect multicollinearity^[http://www.sthda.com/english/articles/39-regression-model-diagnostics/160-multicollinearity-essentials-and-vif-in-r/] in a regression model:
```{r}
car::vif(model_1)
```
### Dealing with multicollinearity
In this section, weâ€™ll update our model by removing the the predictor variables with high VIF values:

VIF score for the predictor variables `Vaccinated` and `Dewormed` is high (VIF = 7.0, 6.2). This might be problematic. As such we will remove them and replace the two with `AllMeds` Since the `AllMeds` variable is a combination of `Vaccinated`, `Dewormed`, and `Steriliezed`, `Sterilized` will also be removed.

```{r}
model_2 <- polr(euth_risk~ Type+(Gender+Color1+MaturitySize+
                                 FurLength+Health+Quantity+
                                 Fee+PhotoAmt+AgeYears+
                                 NumColors+purebreed+
                                 AllMeds), 
              train_data, 
              Hess=TRUE)

summary(model_2)
```

```{r}
car::vif(model_2)
```
### P-values
The polr function doesn't include the p values, as such we need to manually create them as shown below.
```{r}
summary_table <- coef(summary(model_2))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

Here we run another model since there were a number of insignificant variables with high p values.
```{r}
model_3 <- polr(euth_risk~ Type+FurLength+Quantity+
                                 Fee+PhotoAmt+AgeYears+
                                 NumColors+purebreed+
                                 AllMeds, 
              train_data, 
              Hess=TRUE)

summary(model_3)
```
```{r}
summary_table <- coef(summary(model_3))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

Once again, we repeat the process of removing one variable for due to the p values obeserved.
```{r}
model_4 <- polr(euth_risk~ Type+FurLength+Quantity+
                                 Fee+PhotoAmt+AgeYears+purebreed+
                                 AllMeds, 
              train_data, 
              Hess=TRUE)

summary(model_4)
```

```{r}
summary_table <- coef(summary(model_4))
pval <- pnorm(abs(summary_table[, "t value"]),lower.tail = FALSE)* 2
summary_table <- cbind(summary_table, "p value" = round(pval,3))
summary_table
```

### Odds Ratios
These coefficients are called proportional odds ratios and we would interpret these pretty much as we would odds ratios from a binary logistic regression.
```{r}
exp(coef(model_2))
```

### Model Selection
After dealing with multicollinarity and insignificant values, we see that the model with the lowest AIC value of the models created is `model_2` with an AIC of 29952.42.

```{r}
hist(model_2$fitted.values, main = " Histogram ",xlab = "Fitted models", col = 'skyblue3')
```

### Assumptions: Proportional Odds ^[https://www.st-andrews.ac.uk/media/ceed/students/mathssupport/ordinal%20logistic%20regression.pdf]
Brant Test ^[https://cehs-research.github.io/eBook_regression/ordered-logistic-regression-ex-spaking.html#assumptions-1]
The `poTest` function implements tests proposed by Brant (1990) for proportional odds for logistic models fit by the polr() function in the MASS package.
```{r}
car::poTest(model_2)
```

A significant test statistic provides evidence that the parallel regression assumption has been violated.


## Predictions
```{r}
evaluation <- read.csv("https://raw.githubusercontent.com/akarimhammoud/Data_621/main/Final%20Project/data/TestData/test_cleaned.csv")
```

```{r include=FALSE}
#Gender+Color1+MaturitySize+FurLength+Health+Quantity+Fee+PhotoAmt+AgeYears+NumColors+purebreed+Vaccinated+Dewormed+Sterilized

evaluation$AllMeds = evaluation$Vaccinated + evaluation$Dewormed + evaluation$Sterilized

evaluation$Color1 <- recode_factor(evaluation$Color1,"1"= "Black", 
                                "2"= "Brown", 
                                "3"= "Golden", 
                                "4"= "Yellow", 
                                "5"= "Cream", 
                                "6"= "Gray", 
                                "7"= "White")

evaluation$Type <- recode_factor(evaluation$Type, 
                                 "1" = "Dog",
                                 "2"= "Cat")

#data$GenderLabel
evaluation$Gender <- recode_factor(evaluation$Gender, 
                                  "1" = "Male",
                                  "2" = "Female",
                                  "3" = "Mixed")

evaluation$MaturitySize <- recode_factor(evaluation$MaturitySize, "1" = "Small", 
                                   "2" = "Medium",
                                   "3" = "Large",
                                   "4" = "Extra Large")

#1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified
evaluation$Health <-recode_factor(evaluation$Health, 
                                   "1" = "Healthy", 
                                   "2" = "Minor Injury", 
                                   "3" = "Serious Injury")

#FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)
evaluation$FurLength <-recode_factor(evaluation$FurLength, 
                                   "1" = "Short", 
                                   "2" = "Medium", 
                                   "3" = "Long")

evaluation$purebreed <- ifelse(evaluation$Breed1 != 307, "Yes", "No")
evaluation$purebreed <-  as.factor(evaluation$purebreed)

evaluation$NumColors <- as.factor(evaluation$NumColors)
evaluation$AllMeds <- as.factor(evaluation$AllMeds)

evaluation$AgeYears <- as.numeric(evaluation$AgeYears)

evaluation = subset(evaluation, select = -c(Breed1, Color2, Color3, 
                                            Vaccinated, Dewormed, Sterilized, 
                                            State, VideoAmt))
```
After cleaning and selecting the `evalutaion` correpsonding to our `train_data` used in `model_2`, we have:
```{r}
str(evaluation)
```


Below we generate our predictions with the `predict` function ^[https://towardsdatascience.com/implementing-and-interpreting-ordinal-logistic-regression-1ee699274cf5].
```{r}
pred <- predict(model_2, evaluation, type = "p")

head(pred, 1)
```

This model predicts that our Evaluation_Pet will be a medium risk of being euthanized where it will adopted in either months 1, 2 or 3 of being listed.


_____
## References